### Originally from
### https://raw.githubusercontent.com/confluentinc/confluent-kubernetes-examples/refs/heads/master/quickstart-deploy/confluent-platform.yaml
### Extended with JMX configs from grafanacloud
### Original files in `jmx/`
---
apiVersion: platform.confluent.io/v1beta1
kind: Zookeeper
metadata:
  name: zookeeper
  namespace: confluent
spec:
  replicas: 3
  image:
    application: confluentinc/cp-zookeeper:7.8.0
    init: confluentinc/confluent-init-container:2.10.0
  dataVolumeCapacity: 10Gi
  logVolumeCapacity: 10Gi
  metrics:
    prometheus:
      whitelist:
        - 'org.apache.ZooKeeperService:name3=Connections,*'
        - 'org.apache.ZooKeeperService:name3=InMemoryDataTree,*'
        - 'org.apache.ZooKeeperService:name0=*,name1=replica*,name2=*'
        - 'org.apache.ZooKeeperService:name0=*,name1=replica*'
        - 'org.apache.ZooKeeperService:name0=*'
        # If you are running a Standalone Zookeeper, the whitelist objects below would help.
        # If the zookeeper has a quorum, no need to worry about anything else.
        - 'org.apache.ZooKeeperService:name1=InMemoryDataTree,name0=*'
        - 'org.apache.ZooKeeperService:name0=*,name1=Connections,name2=*,name3=*'
      rules:
        # Below rule applies for Zookeeper Cluster having multiple ZK nodes
        # org.apache.ZooKeeperService:name0=*,name3=Connections,name1=*,name2=*,name4=*,name5=*
        - pattern: 'org.apache.ZooKeeperService<name0=(.+), name1=replica.(\\d+), name2=(\\w+), name3=Connections, name4=(.+), name5=(.+)><>([^:]+)'
          name: 'zookeeper_connections_$6'
          labels:
            'server_name': '$1'
            'server_id': $2
            'client_address': '$4'
            'connection_id': '$5'
            'member_type': '$3'
        - pattern: 'org.apache.ZooKeeperService<name0=(.+), name1=replica.(\\d+), name2=(\\w+)><>(\\w+): (\\d+)'
          name: 'zookeeper_$4'
          labels:
            'server_name': '$1'
            'server_id': '$2'
            'member_type': '$3'
        # Below rule applies for Zookeeper Cluster having multiple ZK nodes
        # org.apache.ZooKeeperService:name0=*,name3=InMemoryDataTree
        - pattern: 'org.apache.ZooKeeperService<name0=(.+), name1=replica.(\\d+), name2=(\\w+), name3=InMemoryDataTree><>(WatchCount|NodeCount): (\\d+)'
          name: 'zookeeper_inmemorydatatree_$4'
          type: 'GAUGE'
          labels:
            'server_name': '$1'
            'server_id': '$2'
            'member_type': '$3'
        # Below rule applies for Zookeeper Cluster having multiple ZK nodes
        # org.apache.ZooKeeperService:name0=*,name1=replica*
        - pattern: 'org.apache.ZooKeeperService<name0=(.+), name1=replica.(\\d+)><>(.+): (.+)'
          name: 'zookeeper_status'
          type: 'UNTYPED'
          value: '1'
          labels:
            'server_name': '$1'
            'server_id': '$2'
            '$3': '$4'
        # Below rule applies for Zookeeper Cluster having multiple ZK nodes
        # org.apache.ZooKeeperService:name0=*
        - pattern: 'org.apache.ZooKeeperService<name0=ReplicatedServer_id(\\d+)><>(QuorumSize): (\\d+)'
          name: 'zookeeper_status_$2'
          type: 'GAUGE'
          labels:
            'server_id': '$1'
        # ###########################################################################
        # ###########################################################################
        # Below rule applies to a Standalone ZK
        # org.apache.ZooKeeperService:name0=*,name1=InMemoryDataTree
        - pattern: 'org.apache.ZooKeeperService<name0=(.+), name1=InMemoryDataTree><>(WatchCount|NodeCount): (\\d+)'
          name: 'zookeeper_inmemorydatatree_$2'
          type: 'GAUGE'
          labels:
            'server_name': '$1'
            'server_id': '1'
        # Below rule applies to a Standalone ZK
        # org.apache.ZooKeeperService:name0=*,name1=Connections,name2=*,name3=*
        - pattern: 'org.apache.ZooKeeperService<name0=(.+), name1=Connections, name2=(.+), name3=(.+)><>([^:]+)'
          name: 'zookeeper_connections_$4'
          labels:
            'server_name': '$1'
            'client_address': '$2'
            'connection_id': '$3'
        # Below rule applies to a Standalone ZK
        # org.apache.ZooKeeperService:name0=*
        - pattern: 'org.apache.ZooKeeperService<name0=(.+)><>(StartTime|ClientPort|SecureClientAddress|Version|SecureClientPort): (.+)'
          name: 'zookeeper_$2'
          type: 'GAUGE'
          labels:
            'server_name': '$1'
            '$2': '$3'
        # Below rule applies to a Standalone ZK
        # org.apache.ZooKeeperService:name0=*
        - pattern: 'org.apache.ZooKeeperService<name0=(.+)><>(.+): (.+)'
          name: 'zookeeper_$2'
          type: 'GAUGE'
          labels:
            'server_name': '$1'
            '$2': '$3'

      
---
apiVersion: platform.confluent.io/v1beta1
kind: Kafka
metadata:
  name: kafka
  namespace: confluent
spec:
  replicas: 3
  image:
    application: confluentinc/cp-server:7.8.0
    init: confluentinc/confluent-init-container:2.10.0
  dataVolumeCapacity: 100Gi
  metricReporter:
    enabled: true
  metrics:
    prometheus:
      rules:
        # Special cases and very specific rules
        - pattern: 'kafka.server<type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)><>Value'
          name: 'kafka_server_$1_$2'
          type: 'GAUGE'
          labels:
            'clientId': '$3'
            'topic': '$4'
            'partition': '$5'
        - pattern: 'kafka.server<type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)><>Value'
          name: 'kafka_server_$1_$2'
          type: 'GAUGE'
          labels:
            'clientId': '$3'
            'broker': '$4:$5'

        - pattern: 'kafka.server<type=KafkaRequestHandlerPool, name=RequestHandlerAvgIdlePercent><>OneMinuteRate'
          name: 'kafka_server_kafkarequesthandlerpool_requesthandleravgidlepercent_total'
          type: 'GAUGE'

        - pattern: 'kafka.server<type=socket-server-metrics, clientSoftwareName=(.+), clientSoftwareVersion=(.+), listener=(.+), networkProcessor=(.+)><>connections'
          name: 'kafka_server_socketservermetrics_connections'
          type: 'GAUGE'
          labels:
            'client_software_name': '$1'
            'client_software_version': '$2'
            'listener': '$3'
            'network_processor': '$4'

        - pattern: 'kafka.server<type=socket-server-metrics, listener=(.+), networkProcessor=(.+)><>(.+):'
          name: 'kafka_server_socketservermetrics_$3'
          type: 'GAUGE'
          labels:
            listener: '$1'
            'network_processor': '$2'

        # Count and Value
        - pattern: 'kafka.(.*)<type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)><>(Count|Value)'
          name: 'kafka_$1_$2_$3'
          labels:
            '$4': '$5'
            '$6': '$7'
        - pattern: 'kafka.(.*)<type=(.+), name=(.+), (.+)=(.+)><>(Count|Value)'
          name: 'kafka_$1_$2_$3'
          labels:
            '$4': '$5'
        - pattern: 'kafka.(.*)<type=(.+), name=(.+)><>(Count|Value)'
          name: 'kafka_$1_$2_$3'

        # Percentile
        - pattern: 'kafka.(.*)<type=(.+), name=(.+), (.+)=(.*), (.+)=(.+)><>(\d+)thPercentile'
          name: 'kafka_$1_$2_$3'
          type: 'GAUGE'
          labels:
            '$4': '$5'
            '$6': '$7'
            quantile: '0.$8'
        - pattern: 'kafka.(.*)<type=(.+), name=(.+), (.+)=(.*)><>(\d+)thPercentile'
          name: 'kafka_$1_$2_$3'
          type: 'GAUGE'
          labels:
            '$4': '$5'
            'quantile': '0.$6'
        - pattern: 'kafka.(.*)<type=(.+), name=(.+)><>(\d+)thPercentile'
          name: kafka_$1_$2_$3
          type: 'GAUGE'
          labels:
            quantile: '0.$4'

  dependencies:
    zookeeper:
      endpoint: zookeeper.confluent.svc.cluster.local:2181
---
apiVersion: platform.confluent.io/v1beta1
kind: Connect
metadata:
  name: connect
  namespace: confluent
spec:
  replicas: 1
  image:
    application: confluentinc/cp-server-connect:7.8.0
    init: confluentinc/confluent-init-container:2.10.0
  dependencies:
    kafka:
      bootstrapEndpoint: kafka:9071
  metrics:
    prometheus:
      whitelist:
        # Engine Application Versioning Info
        - kafka.connect:type=app-info,client-id=*
        # Connect Worker Rebalancing info
        - kafka.connect:type=connect-worker-rebalance-metrics
        # Connect Co-ordinator Info
        - kafka.connect:type=connect-coordinator-metrics,*
        - kafka.connect:type=connect-metrics,*
        # Worker level metrics for the aggregate as well as per connector level
        - kafka.connect:type=connect-worker-metrics
        - kafka.connect:type=connect-worker-metrics,*
        # Engine Connector Versioning Info
        - kafka.connect:type=connector-metrics,*
        # Task level metrics for every connector running in the current node.
        - kafka.connect:type=*-task-metrics,*
        - kafka.connect:type=task-error-metrics,*
        #  Confluent Replicator JMX Stats
        - confluent.replicator:type=confluent-replicator-task-metrics,*
        # The two lines below are used to pull the Kafka Client Producer & consumer metrics from Connect Workers.
        # If you care about Producer/Consumer metrics for Connect, please uncomment 2 lines below.
        # Please note that this increases the scrape duration by about 1-2 seconds as it needs to parse a lot of data.
        - 'kafka.consumer:*'
        - 'kafka.producer:*'
      blacklist:
        # This will ignore the admin client metrics from KSQL server and will blacklist certain metrics
        # that do not make sense for ingestion.
        - 'kafka.admin.client:*'
        - 'kafka.consumer:type=*,id=*'
        - 'kafka.producer:type=*,id=*'
        - 'kafka.producer:client-id=confluent.monitoring*,*'
        - 'kafka.*:type=kafka-metrics-count,*'
      rules:
        # 'kafka.schema.registry:type=app-info,id=*'
        - pattern: 'kafka.connect<type=app-info, client-id=(.+)><>(.+): (.+)'
          name: 'kafka_connect_app_info'
          value: '1'
          labels:
            client-id: '$1'
            '$2': '$3'
          type: 'UNTYPED'
        # kafka.connect:type=connect-worker-rebalance-metrics
        - pattern: 'kafka.connect<type=connect-worker-rebalance-metrics><>([^:]+)'
          name: 'kafka_connect_connect_worker_rebalance_metrics_$1'
        # kafka.connect:type=connect-coordinator-metrics,client-id=*
        # kafka.connect:type=connect-metrics,client-id=*
        - pattern: 'kafka.connect<type=(.+), client-id=(.+)><>([^:]+)'
          name: kafka_connect_$1_$3
          labels:
            client_id: $2
        # kafka.connect:type=connect-worker-metrics
        - pattern: 'kafka.connect<type=connect-worker-metrics><>([^:]+)'
          name: kafka_connect_connect_worker_metrics_$1
          labels:
            connector: 'aggregate'
        # kafka.connect:type=connect-worker-metrics,connector=*
        - pattern: 'kafka.connect<type=connect-worker-metrics, connector=(.+)><>([^:]+)'
          name: kafka_connect_connect_worker_metrics_$2
          labels:
            connector: $1
        # kafka.connect:type=connector-metrics,connector=*
        - pattern: 'kafka.connect<type=connector-metrics, connector=(.+)><>(.+): (.+)'
          value: '1'
          name: kafka_connect_connector_metrics
          labels:
            connector: $1
            '$2': $3
          type: 'UNTYPED'
        # kafka.connect:type=*-task-metrics,*
        # kafka.connect:type=source-task-metrics,connector=*,task=*
        # kafka.connect:type=sink-task-metrics,connector=*,task=*
        # kafka.connect:type=connector-task-metrics,connector=*,task=*
        - pattern: 'kafka.connect<type=(.+)-task-metrics, connector=(.+), task=(\\d+)><>(.+): (.+)'
          name: kafka_connect_$1_task_metrics_$4
          labels:
            connector: '$2'
            task: '$3'
        # kafka.connect:type=task-error-metrics,*
        # kafka.connect:type=task-error-metrics,connector=*,task=*
        - pattern: 'kafka.connect<type=task-error-metrics, connector=(.+), task=(\\d+)><>([^:]+)'
          name: kafka_connect_task_error_metrics_$3
          labels:
            connector: '$1'
            task: '$2'
        # confluent.replicator:type=confluent-replicator-task-metrics,* : confluent-replicator-task-topic-partition-*: Number Values
        - pattern: 'confluent.replicator<type=confluent-replicator-task-metrics, confluent-replicator-(.*)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+)><>confluent-replicator-task-topic-partition-(.*): (.*)'
          name: confluent_replicator_task_metrics_$9
          labels:
            $1: '$2'
            $3: '$4'
            $5: '$6'
            $7: '$8'
        # confluent.replicator:type=confluent-replicator-task-metrics,* : Strings
        - pattern: 'confluent.replicator<type=confluent-replicator-task-metrics, confluent-replicator-(.*)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+), confluent-replicator-(.+)=(.+)><>(confluent-replicator-destination-cluster|confluent-replicator-source-cluster|confluent-replicator-destination-topic-name): (.*)'
          name: confluent_replicator_task_metrics_info
          value: '1'
          labels:
            $1: '$2'
            $3: '$4'
            $5: '$6'
            $7: '$8'
            $9: '$10'
        # 'kafka.consumer:type=app-info,client-id=*'
        # 'kafka.producer:type=app-info,client-id=*'
        - pattern: 'kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)'
          value: '1'
          name: kafka_$1_app_info
          labels:
            client_type: $1
            client_id: $2
            $3: $4
          type: 'UNTYPED'
        # 'kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*'
        # 'kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*'
        # 'kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$9
          type: GAUGE
          labels:
            client_type: $1
            $3: '$4'
            $5: '$6'
            $7: '$8'
        # 'kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*'
        # 'kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*'
        # 'kafka.producer:type=producer-node-metrics,client-id=*, node-id=*'
        # 'kafka.producer:type=producer-topic-metrics,client-id=*, topic=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$7
          type: 'GAUGE'
          labels:
            client_type: $1
            $3: '$4'
            $5: '$6'
        # 'kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*'
        # 'kafka.consumer:type=consumer-metrics,client-id=*'
        # 'kafka.producer:type=producer-metrics,client-id=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$5
          type: 'GAUGE'
          labels:
            client_type: $1
            $3: '$4'
        - pattern: 'kafka.(.+)<type=(.+)><>(.+):'
          name: kafka_$1_$2_$3
          labels:
            client_type: $1

---
apiVersion: platform.confluent.io/v1beta1
kind: KsqlDB
metadata:
  name: ksqldb
  namespace: confluent
spec:
  replicas: 1
  image:
    application: confluentinc/cp-ksqldb-server:7.8.0
    init: confluentinc/confluent-init-container:2.10.0
  dataVolumeCapacity: 10Gi
  metrics:
    prometheus:
      whitelist:
        - 'io.confluent.ksql.metrics:*'
        # The two lines below are used to pull the Kafka Client Producer & consumer metrics from KSQL Client.
        # If you care about Producer/Consumer metrics for KSQL, please uncomment 2 lines below.
        # Please note that this increases the scrape duration to about 1 second as it needs to parse a lot of data.
        - 'kafka.consumer:*'
        - 'kafka.producer:*'
        - 'kafka.streams:*'
      blacklist:
        - kafka.streams:type=kafka-metrics-count
        # This will ignore the admin client metrics from KSQL server and will blacklist certain metrics
        # that do not make sense for ingestion.
        - 'kafka.admin.client:*'
        - 'kafka.consumer:type=*,id=*'
        - 'kafka.consumer:type=*,client-id=*'
        - 'kafka.consumer:type=*,client-id=*,node-id=*'
        - 'kafka.producer:type=*,id=*'
        - 'kafka.producer:type=*,client-id=*'
        - 'kafka.producer:type=*,client-id=*,node-id=*'
        - 'kafka.streams:type=stream-processor-node-metrics,thread-id=*,task-id=*,processor-node-id=*'
        - 'kafka.*:type=kafka-metrics-count,*'
      rules:
        # 'io.confluent.ksql.metrics:type=producer-metrics,key=*,id=*'
        # 'io.confluent.ksql.metrics:type=consumer-metrics,key=*,id=*'
        - pattern: io.confluent.ksql.metrics<type=(.+), key=(.+), id=(.+)><>([^:]+)
          name: ksql_$1_$4
          labels:
            key: '$2'
            id: '$3'
        # 'io.confluent.ksql.metrics:type=_confluent-ksql-<cluster-id>ksql-engine-query-stats'
        # The below statement parses KSQL Cluster Name and adds a new label so that per cluster data is searchable.
        - pattern: io.confluent.ksql.metrics<type=_confluent-ksql-(.+)ksql-engine-query-stats><>([^:]+)
          name: 'ksql_ksql_engine_query_stats_$2'
          labels:
            ksql_cluster: $1
        # 'io.confluent.ksql.metrics:type=ksql-queries,status=_confluent-ksql-<cluser-id>_query_<query>
        # The below statement parses KSQL query specific status
        - pattern: 'io.confluent.ksql.metrics<type=(.+), status=_confluent-ksql-(.+)query_(.+)><>(.+): (.+)'
          value: '1'
          name: ksql_ksql_metrics_$1_$4
          labels:
            ksql_query: $3
            ksql_cluster: $2
            $4: $5
        # kafka.streams:type=stream-processor-node-metrics,processor-node-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-record-cache-metrics,record-cache-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-state-metrics,rocksdb-state-id=*,task-id=*,thread-id=*
        # kafka.streams:type=stream-state-metrics,rocksdb-state-id=*,task-id=*,thread-id=*
        - pattern: 'kafka.streams<type=(.+), thread-id=(.+), task-id=(.+), (.+)=(.+)><>(.+):'
          name: kafka_streams_$1_$6
          type: 'GAUGE'
          labels:
            thread_id: '$2'
            task_id: '$3'
            $4: '$5'
        # kafka.streams:type=stream-task-metrics,task-id=*,thread-id=*
        - pattern: 'kafka.streams<type=(.+), thread-id=(.+), task-id=(.+)><>(.+):'
          name: kafka_streams_$1_$4
          type: 'GAUGE'
          labels:
            thread_id: '$2'
            task_id: '$3'
        # kafka.streams:type=stream-metrics,client-id=*
        - pattern: 'kafka.streams<type=stream-metrics, (.+)=(.+)><>(state|alive-stream-threads|commit-id|version|application-id): (.+)'
          name: kafka_streams_stream_metrics
          value: '1'
          type: 'UNTYPED'
          labels:
            $1: '$2'
            $3: '$4'
        # kafka.streams:type=stream-thread-metrics,thread-id=*
        - pattern: 'kafka.streams<type=(.+), (.+)=(.+)><>([^:]+)'
          name: kafka_streams_$1_$4
          type: 'GAUGE'
          labels:
            '$2': '$3'
        # 'kafka.consumer:type=app-info,client-id=*'
        # 'kafka.producer:type=app-info,client-id=*'
        - pattern: 'kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)'
          value: '1'
          name: kafka_$1_app_info
          labels:
            client_type: $1
            client_id: $2
            $3: $4
          type: 'UNTYPED'
        # 'kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*'
        # 'kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*'
        # 'kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$9
          type: 'GAUGE'
          labels:
            client_type: $1
            $3: '$4'
            $5: '$6'
            $7: '$8'
        # 'kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*'
        # 'kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*'
        # 'kafka.producer:type=producer-node-metrics,client-id=*, node-id=*'
        # 'kafka.producer:type=producer-topic-metrics,client-id=*, topic=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$7
          type: 'GAUGE'
          labels:
            client_type: $1
            $3: '$4'
            $5: '$6'
        # 'kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*'
        # 'kafka.consumer:type=consumer-metrics,client-id=*'
        # 'kafka.producer:type=producer-metrics,client-id=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$5
          type: 'GAUGE'
          labels:
            client_type: $1
            $3: '$4'
        - pattern: 'kafka.(.+)<type=(.+)><>(.+):'
          name: kafka_$1_$2_$3
          labels:
            client_type: $1

---
apiVersion: platform.confluent.io/v1beta1
kind: ControlCenter
metadata:
  name: controlcenter
  namespace: confluent
spec:
  replicas: 1
  image:
    application: confluentinc/cp-enterprise-control-center:7.8.0
    init: confluentinc/confluent-init-container:2.10.0
  dataVolumeCapacity: 10Gi
  dependencies:
    schemaRegistry:
      url: http://schemaregistry.confluent.svc.cluster.local:8081
    ksqldb:
    - name: ksqldb
      url: http://ksqldb.confluent.svc.cluster.local:8088
    connect:
    - name: connect
      url: http://connect.confluent.svc.cluster.local:8083
---
apiVersion: platform.confluent.io/v1beta1
kind: SchemaRegistry
metadata:
  name: schemaregistry
  namespace: confluent
spec:
  replicas: 3
  image:
    application: confluentinc/cp-schema-registry:7.8.0
    init: confluentinc/confluent-init-container:2.10.0
  metrics:
    prometheus:
      whitelist:
        - kafka.schema.registry:type=jetty-metrics
        - kafka.schema.registry:type=jersey-metrics
        - kafka.schema.registry:type=app-info,id=*
        - kafka.schema.registry:type=registered-count
        - kafka.schema.registry:type=json-schema*
        - kafka.schema.registry:type=protobuf-schemas*
        - kafka.schema.registry:type=avro-schemas*
        - kafka.schema.registry:type=kafka.schema.registry-metrics,client-id=*
        - kafka.schema.registry:type=kafka.schema.registry-coordinator-metrics,client-id=*
        # The two lines below are used to pull the Kafka Client Producer & consumer metrics from SR Client.
        # If you care about Producer/Consumer metrics for SR, please uncomment 2 lines below.
        # Please note that this increases the scrape duration to about 1 second as it needs to parse a lot of data.
        - 'kafka.consumer:*'
        - 'kafka.producer:*'
      blacklist:
        # This will ignore the admin client metrics from SR server and will blacklist certain metrics
        # that do not make sense for ingestion.
        - kafka.producer:type=app-info,client-id=*
        - kafka.consumer:type=app-info,client-id=*
        - 'kafka.admin.client:*'
        - 'kafka.consumer:type=*,id=*'
        - 'kafka.producer:type=*,id=*'
        # - 'kafka.producer:client-id=confluent.monitoring*,*'
        # - 'kafka.producer:client-id=confluent-license*,*'
        - 'kafka.*:type=kafka-metrics-count,*'
      rules:
        # 'kafka.schema.registry:type=jetty-metrics'
        - pattern: 'kafka.schema.registry<type=jetty-metrics>([^:]+):'
          name: 'kafka_schema_registry_jetty_metrics_$1'
        # 'kafka.schema.registry:type=jersey-metrics'
        - pattern: 'kafka.schema.registry<type=jersey-metrics>([^:]+):'
          name: 'kafka_schema_registry_jersey_metrics_$1'
        # 'kafka.schema.registry:type=app-info,id=*'
        - pattern: 'kafka.schema.registry<type=app-info, id=(.+)><>(.+): (.+)'
          name: 'kafka_schema_registry_app_info'
          value: '1'
          labels:
            client-id: '$1'
            '$2': '$3'
          type: 'UNTYPED'
        # 'kafka.schema.registry:type=registered-count'
        - pattern: 'kafka.schema.registry<type=registered-count>([^:]+):'
          name: 'kafka_schema_registry_registered_count'
        # 'kafka.schema.registry:type=json-schemas-created'
        # 'kafka.schema.registry:type=json-schemas-deleted'
        # 'kafka.schema.registry:type=protobuf-schemas-created'
        # 'kafka.schema.registry:type=protobuf-schemas-deleted'
        # 'kafka.schema.registry:type=avro-schemas-created'
        # 'kafka.schema.registry:type=avro-schemas-deleted'
        - pattern: 'kafka.schema.registry<type=(\\w+)-schemas-(\\w+)>([^:]+):'
          name: 'kafka_schema_registry_schemas_$2'
          labels:
            schema_type: $1
        # kafka.schema.registry:type=kafka.schema.registry-metrics,client-id=*
        # kafka.schema.registry:type=kafka.schema.registry-coordinator-metrics,client-id=*
        - pattern: 'kafka.schema.registry<type=(.+), client-id=(.+)><>([^:]+):'
          name: 'kafka_schema_registry_$1_$3'
          labels:
            client_id: $2
        # 'kafka.consumer:type=app-info,client-id=*'
        # 'kafka.producer:type=app-info,client-id=*'
        - pattern: 'kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)'
          value: '1'
          name: kafka_$1_app_info
          labels:
            client_type: $1
            client_id: $2
            $3: $4
          type: 'UNTYPED'
        # 'kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*'
        # 'kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*'
        # 'kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$9
          type: 'GAUGE'
          labels:
            client_type: $1
            $3: '$4'
            $5: '$6'
            $7: '$8'
        # 'kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*'
        # 'kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*'
        # 'kafka.producer:type=producer-node-metrics,client-id=*, node-id=*'
        # 'kafka.producer:type=producer-topic-metrics,client-id=*, topic=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$7
          type: 'GAUGE'
          labels:
            client_type: $1
            $3: '$4'
            $5: '$6'
        # 'kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*'
        # 'kafka.consumer:type=consumer-metrics,client-id=*'
        # 'kafka.producer:type=producer-metrics,client-id=*'
        - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):'
          name: kafka_$1_$2_$5
          type: 'GAUGE'
          labels:
            client_type: $1
            $3: '$4'
        - pattern: 'kafka.(.+)<type=(.+)><>(.+):'
          name: kafka_$1_$2_$3
          labels:
            client_type: $1

---
apiVersion: platform.confluent.io/v1beta1
kind: KafkaRestProxy
metadata:
  name: kafkarestproxy
  namespace: confluent
spec:
  replicas: 1
  image:
    application: confluentinc/cp-kafka-rest:7.8.0
    init: confluentinc/confluent-init-container:2.10.0
  dependencies:
    schemaRegistry:
      url: http://schemaregistry.confluent.svc.cluster.local:8081
